{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install **kubectl** and the **Google Cloud SDK** with the necessary authentication plugin for Google Kubernetes Engine (GKE)."
      ],
      "metadata": {
        "id": "MJkq3GeyosAI"
      },
      "id": "MJkq3GeyosAI"
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\n",
        "sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl\n",
        "apt-get update && apt-get install apt-transport-https ca-certificates gnupg\n",
        "curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo gpg --dearmor -o /usr/share/keyrings/cloud.google.gpg\n",
        "echo \"deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main\" | sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list\n",
        "apt-get update && sudo apt-get install google-cloud-cli-gke-gcloud-auth-plugin\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tiGscdCpo2KC",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1716459651838,
          "user_tz": -120,
          "elapsed": 11442,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "ff824e08-14bf-4ffb-936e-fa586015fe81"
      },
      "id": "tiGscdCpo2KC",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 https://packages.cloud.google.com/apt cloud-sdk InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Fetched 229 kB in 1s (172 kB/s)\n",
            "Reading package lists...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "ca-certificates is already the newest version (20230311ubuntu0.22.04.1).\n",
            "gnupg is already the newest version (2.2.27-3ubuntu2.1).\n",
            "apt-transport-https is already the newest version (2.4.12).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.\n",
            "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main\n",
            "Hit:1 https://packages.cloud.google.com/apt cloud-sdk InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "google-cloud-cli-gke-gcloud-auth-plugin is already the newest version (477.0.0-0).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100   138  100   138    0     0   2138      0 --:--:-- --:--:-- --:--:--  2156\n",
            "\r100 49.0M  100 49.0M    0     0   118M      0 --:--:-- --:--:-- --:--:--  118M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0gpg: cannot open '/dev/tty': No such device or address\n",
            "\r100  2659  100  2659    0     0  36694      0 --:--:-- --:--:-- --:--:-- 36930\n",
            "curl: (23) Failed writing body\n",
            "W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2\n",
            "W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2\n",
            "W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2\n",
            "W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2\n",
            "W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2\n",
            "W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrieves the GKE cluster's credentials using the **gcloud** command:"
      ],
      "metadata": {
        "id": "Q8x_lxTXrZTi"
      },
      "id": "Q8x_lxTXrZTi"
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "export KUBERNETES_CLUSTER_NAME=\"nltosql-dima\"\n",
        "gcloud container clusters get-credentials $KUBERNETES_CLUSTER_NAME --region $GOOGLE_CLOUD_REGION"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1c8Fsk1rcrK",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1716458517839,
          "user_tz": -120,
          "elapsed": 1203,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "551cbaf9-0498-44fc-e0d0-688c41dc3d34"
      },
      "id": "n1c8Fsk1rcrK",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching cluster endpoint and auth data.\n",
            "kubeconfig entry generated for nltosql-dima.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create an .env file with environment variables required for connecting to Postgresql and LLM runtime in a Kubernetes cluster."
      ],
      "metadata": {
        "id": "USwAo2Nwr9wQ"
      },
      "id": "USwAo2Nwr9wQ"
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "echo POSTGRES_ENDPOINT=$(kubectl get pod -l spilo-role=master -n postgres -o=jsonpath=\"{.items[0].status.podIP}\") > .env\n",
        "echo LLM_ENDPOINT=http://$(kubectl get pod -l app=tgi-runtime -n llm -o=jsonpath=\"{.items[0].status.podIP}\"):8000 >> .env\n",
        "echo DATABASE_NAME=mydatabase >> .env\n",
        "echo DBUSERNAME=$(kubectl get secret mydatabaseowner.my-cluster.credentials.postgresql.acid.zalan.do -n postgres --template={{.data.username}} | base64 -d) >> .env\n",
        "echo DBPASSWORD=$(kubectl get secret mydatabaseowner.my-cluster.credentials.postgresql.acid.zalan.do -n postgres --template={{.data.password}} | base64 -d) >> .env"
      ],
      "metadata": {
        "id": "6lo6M4AqsAru",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1716460066445,
          "user_tz": -120,
          "elapsed": 1696,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "6lo6M4AqsAru",
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install required python libraries:"
      ],
      "metadata": {
        "id": "xX-aQbhl4g4C"
      },
      "id": "xX-aQbhl4g4C"
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install python-dotenv psycopg-binary psycopg tabulate text-generation langchain langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwspErB44izG",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1716458594128,
          "user_tz": -120,
          "elapsed": 19693,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "09fb9da5-c595-4db9-b9ca-3d26fa54d5b9"
      },
      "id": "uwspErB44izG",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Collecting psycopg-binary\n",
            "  Downloading psycopg_binary-3.1.19-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psycopg\n",
            "  Downloading psycopg-3.1.19-py3-none-any.whl (179 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.4/179.4 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
            "Collecting text-generation\n",
            "  Downloading text_generation-0.7.0-py3-none-any.whl (12 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.2.0-py3-none-any.whl (973 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.7/973.7 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-community\n",
            "  Downloading langchain_community-0.2.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.1 in /usr/local/lib/python3.10/dist-packages (from psycopg) (4.11.0)\n",
            "Requirement already satisfied: aiohttp<4.0,>=3.8 in /usr/local/lib/python3.10/dist-packages (from text-generation) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from text-generation) (0.20.3)\n",
            "Collecting pydantic<3,>2 (from text-generation)\n",
            "  Downloading pydantic-2.7.1-py3-none-any.whl (409 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.3/409.3 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
            "Collecting langchain-core<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_core-0.2.1-py3-none-any.whl (308 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.5/308.5 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.0-py3-none-any.whl (23 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.62-py3-none-any.whl (122 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.3/122.3 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.8->text-generation) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.8->text-generation) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.8->text-generation) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.8->text-generation) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.8->text-generation) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.12->text-generation) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.12->text-generation) (2023.6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.12->text-generation) (4.66.4)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.12->text-generation) (24.0)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.0->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting packaging>=20.9 (from huggingface-hub<1.0,>=0.12->text-generation)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>2->text-generation) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>2->text-generation) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: psycopg-binary, psycopg, packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, pydantic, marshmallow, jsonpatch, text-generation, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain, langchain-community\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.15\n",
            "    Uninstalling pydantic-1.10.15:\n",
            "      Successfully uninstalled pydantic-1.10.15\n",
            "Successfully installed dataclasses-json-0.6.6 jsonpatch-1.33 jsonpointer-2.4 langchain-0.2.0 langchain-community-0.2.0 langchain-core-0.2.1 langchain-text-splitters-0.2.0 langsmith-0.1.62 marshmallow-3.21.2 mypy-extensions-1.0.0 orjson-3.10.3 packaging-23.2 psycopg-3.1.19 psycopg-binary-3.1.19 pydantic-2.7.1 text-generation-0.7.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import python libraries:"
      ],
      "metadata": {
        "id": "9acUeBu15quS"
      },
      "id": "9acUeBu15quS"
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "import psycopg\n",
        "import os\n",
        "from tabulate import tabulate\n",
        "from langchain_community.llms import HuggingFaceTextGenInference\n",
        "from langchain_core.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "oqq4NDgvt-XT",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1716458612004,
          "user_tz": -120,
          "elapsed": 1593,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "oqq4NDgvt-XT",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load environment variables from the .env file, establish a connection to a PostgreSQL database and retrieve information about the schema of the public tables."
      ],
      "metadata": {
        "id": "Ef9FSgl55_MI"
      },
      "id": "Ef9FSgl55_MI"
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv()\n",
        "\n",
        "conn = psycopg.connect(\n",
        "    dbname=os.environ.get(\"DATABASE_NAME\"),\n",
        "    host=os.environ.get(\"POSTGRES_ENDPOINT\"),\n",
        "    user=os.environ.get(\"DBUSERNAME\"),\n",
        "    password=os.environ.get(\"DBPASSWORD\"),\n",
        "    autocommit=True)\n",
        "\n",
        "db_schema = conn.execute(\"SELECT table_name, column_name as Columns, data_type as DataTypes FROM  information_schema.columns where table_name NOT LIKE 'pg_stat%' AND table_schema='public' order by table_name,column_name;\")\n",
        "colnames = [desc[0] for desc in db_schema.description]\n",
        "db_schema_formatted=tabulate(db_schema.fetchall(), headers=colnames, tablefmt='psql')\n"
      ],
      "metadata": {
        "id": "7M-IQwbM6AgY",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1716460212145,
          "user_tz": -120,
          "elapsed": 495,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "7M-IQwbM6AgY",
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializes the Hugging Face TGI connection for text generation.\n",
        "\n",
        "Set up two prompts: the first one is for generating SQL commands based on user queries, while the second prompt is for generating responses based on user queries and PostgreSQL replies."
      ],
      "metadata": {
        "id": "9bLuIcNU6sz7"
      },
      "id": "9bLuIcNU6sz7"
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceTextGenInference(\n",
        "    inference_server_url=os.environ.get(\"LLM_ENDPOINT\"),\n",
        "    temperature=0.5,\n",
        "    top_k=5,\n",
        "    top_p=0.5,\n",
        "    repetition_penalty=1.03,\n",
        ")\n",
        "\n",
        "sql_prompt_template = PromptTemplate.from_template(\"\"\"\n",
        "    <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "    You are a helpful AI assistant that can transform user queries into SQL commands to retrieve the data from the Postgresql database. The database has the next tables schema:\n",
        "    {db_schema}\n",
        "    Please prepare and return only the SQL command, based on the user query, without any formatting or newlines. The answer must contain only valid SQL command.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "    {query}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\"\"\")\n",
        "\n",
        "final_prompt_template = PromptTemplate.from_template(\"\"\"\n",
        "    <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "    You are a helpful AI assistant that can understand Postgresql replies and explain this data to the user. The database has the next tables schema:\n",
        "    {db_schema}\n",
        "    User query: {query}\n",
        "    Postgresql reply:\n",
        "    {postgres_reply}\n",
        "    Base your answer on the provided user query and Postgresql reply.\n",
        "    Generate a draft response using the selected information.\n",
        "    It should be easy to understand your answer. Don't add any introductory words, start answering right away.\n",
        "    Keep your answer to a one or two sentences (if possible) that specifically answers the user's question. If not - try to keep the answer short, summarizing the returned data.\n",
        "    Generate your final response after adjusting it to increase accuracy and relevance.\n",
        "    Now only show your final response!\n",
        "    If you do not know the answer or context is not relevant, response with \"I don't know\".\n",
        "    <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "RKLr5riV6uZW",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1716460319140,
          "user_tz": -120,
          "elapsed": 1,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "RKLr5riV6uZW",
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configure two functions to interacte with the PostgreSQL database and the TGI runtime."
      ],
      "metadata": {
        "id": "vdtggWOO7Wef"
      },
      "id": "vdtggWOO7Wef"
    },
    {
      "cell_type": "code",
      "source": [
        "def postgres_query(query):\n",
        "    try:\n",
        "        postgres_reply = conn.execute(query)\n",
        "    except psycopg.Error as e:\n",
        "        print(\"Unable to process query\")\n",
        "        return False\n",
        "    colnames = [desc[0] for desc in postgres_reply.description]\n",
        "    postgres_reply_data = postgres_reply.fetchall()\n",
        "    if postgres_reply_data == []:\n",
        "        print(\"Received empty SQL answer\")\n",
        "        return False\n",
        "    postgres_reply_formatted=tabulate(postgres_reply_data, headers=colnames, tablefmt='psql')\n",
        "    return postgres_reply_formatted\n",
        "\n",
        "\n",
        "def llm_query(query):\n",
        "    sql_prompt_value=sql_prompt_template.format(db_schema=db_schema_formatted, query=query)\n",
        "    sql_query=llm.invoke(sql_prompt_value)\n",
        "    # print(sql_query)\n",
        "    postgres_reply=postgres_query(sql_query)\n",
        "    if postgres_reply == False:\n",
        "        return \"Try another query\"\n",
        "    # print(postgres_reply)\n",
        "    final_prompt_value=final_prompt_template.format(db_schema=db_schema_formatted, query=query, postgres_reply=postgres_reply)\n",
        "    return llm.invoke(final_prompt_value)"
      ],
      "metadata": {
        "id": "a_6XVEtH7dFv",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1716459014750,
          "user_tz": -120,
          "elapsed": 328,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "a_6XVEtH7dFv",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run some queries to demonstrate the moability to generate SQL commands from user queries and provide responses based on the PostgreSQL replies:"
      ],
      "metadata": {
        "id": "LMMBr-gu7g0I"
      },
      "id": "LMMBr-gu7g0I"
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm_query(\"Please calculate the total sum of all John transactions.\"))\n",
        "print(llm_query(\"Which woman spent more money in 2023 and how much?\"))\n",
        "print(llm_query(\"What is the capital of Great Britain?\"))\n",
        "print(llm_query(\"Who spent more money on electronics in last month?\"))\n",
        "print(llm_query(\"Who spent more money on electronics in 10 last months?\"))\n",
        "print(llm_query(\"Give me top 3 buyers of clothing. How much money each person spent?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQZ1gUYY7iLn",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1716459463391,
          "user_tz": -120,
          "elapsed": 29595,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "b6dd1d33-dcbf-4bef-cb1f-304c31d6171e"
      },
      "id": "HQZ1gUYY7iLn",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total sum of all John's transactions is 6210.\n",
            "Elizabeth spent $15,950 in 2023.\n",
            "Unable to process query\n",
            "Try another query\n",
            "Received empty SQL answer\n",
            "Try another query\n",
            "Elizabeth spent the most money on electronics in the last 10 months, with a total amount of $5750.\n",
            "The top 3 buyers of clothing are Brenda, Melissa, and Sarah, who spent $7755, $7550, and $5775 respectively.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "dmitrii_ganochenko (May 23, 2024, 10:47:16 AM)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}