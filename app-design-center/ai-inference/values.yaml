# Copyright 2026 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Default values for gemma-inference.
replicaCount: 1

image:
  repository: us-docker.pkg.dev/cloudrun/container/gemma/gemma3-4b
  tag: latest
  pullPolicy: IfNotPresent

nameOverride: ""
fullnameOverride: ""

serviceAccount:
  create: true
  name: ""

podAnnotations: {}

podSecurityContext: {}
  # fsGroup: 2000

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

service:
  type: LoadBalancer
  port: 8000
  targetPort: 8000
  annotations: {}

resources:
  limits:
    nvidia.com/gpu: 1
    memory: "16Gi"
    cpu: "8"
  requests:
    nvidia.com/gpu: 1
    memory: "16Gi"
    cpu: "8"

nodeSelector:
  cloud.google.com/gke-accelerator: nvidia-l4

tolerations:
- key: "nvidia.com/gpu"
  operator: "Exists"
  effect: "NoSchedule"

autoscaling:
  enabled: true
  minReplicas: 1
  maxReplicas: 3
  targetGPUUtilization: 80

podMonitoring:
  enabled: true
  interval: 60s

env:
  OLLAMA_HOST: "0.0.0.0:8000"
  OLLAMA_MAX_LOADED_MODELS: "1"
  OLLAMA_KEEP_ALIVE: "-1"